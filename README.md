# LLM/VLM 질문 시스템 실행 방법

1. **필수 패키지 설치**
   ```
   pip install -r requirements.txt
   ```

2. **새로운 터미널에서 Ollama 서버 실행**
   ```
   ollama serve
   ```

3. **기존 터미널에서 서버 실행**
   ```
   python main.py
   ```

4. **안내된 주소에 접속하여 질문 입력 후 사용 가능합니다.**
